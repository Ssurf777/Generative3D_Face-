{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1brWAfyJQxaQjd-e50B88nnNePUQy6tkB",
      "authorship_tag": "ABX9TyNXB/5bCKIuZtplEdprJ8nO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ssurf777/Generative3D_Face_VAE/blob/main/VAE_face_emotional_logging_wandb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install POT\n",
        "!pip install open3d"
      ],
      "metadata": {
        "id": "fpKrr8THlVRk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: wandbのpip install\n",
        "!pip install wandb"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sw6srmqigcqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VAE"
      ],
      "metadata": {
        "id": "rCIaoVXvzkeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "\n",
        "def download_file(url, local_filename):\n",
        "    \"\"\"Downloads a file from a URL to a local file.\"\"\"\n",
        "    print(f\"Downloading {url}...\")\n",
        "    try:\n",
        "        with requests.get(url, stream=True) as r:\n",
        "            r.raise_for_status()\n",
        "            with open(local_filename, 'wb') as f:\n",
        "                for chunk in r.iter_content(chunk_size=4096):  # Smaller chunk size\n",
        "                    f.write(chunk)\n",
        "        print(f\"{local_filename} downloaded successfully.\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Failed to download {local_filename}: {e}\")\n",
        "\n",
        "# URLs for downloading\n",
        "urls = {\n",
        "    \"utils.py\": \"https://raw.githubusercontent.com/Ssurf777/Generative3D_Face_VAE/refs/heads/main/lib/utils.py\",\n",
        "    \"ply_dataloader.py\": \"https://raw.githubusercontent.com/Ssurf777/Generative3D_Face_VAE/refs/heads/main/lib/ply_dataloader.py\",\n",
        "    \"sampling.py\": \"https://raw.githubusercontent.com/Ssurf777/Generative3D_Face_VAE/refs/heads/main/lib/sampling.py\",\n",
        "    \"ISAB_VQVAE.py\": \"https://raw.githubusercontent.com/Ssurf777/Generative3D_Face_VAE/refs/heads/main/lib/ISAB_VQVAE.py\",\n",
        "    \"ChamferDis.py\": \"https://raw.githubusercontent.com/Ssurf777/Generative3D_Face_VAE/refs/heads/main/lib/ChamferDis.py\",\n",
        "    \"EarthMoversDis.py\": \"https://raw.githubusercontent.com/Ssurf777/Generative3D_Face_VAE/refs/heads/main/lib/EarthMoversDis.py\",\n",
        "    \"visualize_loss.py\": \"https://raw.githubusercontent.com/Ssurf777/Generative3D_Face_VAE/refs/heads/main/lib/visualize_loss.py\",\n",
        "    \"ISAB.py\": \"https://raw.githubusercontent.com/Ssurf777/Generative3D_Face_VAE/refs/heads/main/lib/ISAB.py\",\n",
        "}\n",
        "\n",
        "# Download each file\n",
        "for local_filename, url in urls.items():\n",
        "    download_file(url, local_filename)\n",
        "\n"
      ],
      "metadata": {
        "id": "W5QT-a70lWC9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import torch\n",
        "import wandb\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Import downloaded modules\n",
        "import utils\n",
        "import sampling\n",
        "import ISAB_VQVAE\n",
        "import ISAB\n",
        "import ply_dataloader\n",
        "import ChamferDis\n",
        "import EarthMoversDis\n",
        "import visualize_loss\n",
        "\n",
        "from utils import get_available_memory\n",
        "from sampling import PointSampler\n",
        "from ISAB import MultiheadAttentionBlock, ISAB\n",
        "from ISAB_VQVAE import ISAB_VQVAE\n",
        "from ply_dataloader import prepare_data_from_ply\n",
        "from ChamferDis import chamfer_distance\n",
        "from EarthMoversDis import emd_distance\n",
        "from visualize_loss import visualize_loss\n",
        "\n",
        "available_memory_gb = get_available_memory()\n",
        "print(f\"Available memory: {available_memory_gb:.2f} GB\")"
      ],
      "metadata": {
        "id": "6ZVKgzqUlY1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "id": "fYwaCDnjhpBz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"Face_emotional_using_VAE\", entity=\"\") # Replace with your project name and username"
      ],
      "metadata": {
        "id": "B-X5-b2QhMTR",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "ibUhRpkOWK_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "num_points =5000\n",
        "# データ準備\n",
        "file_names = []\n",
        "for i in range(10, 171, 10):\n",
        "  file_names.append(f\"/content/drive/MyDrive/Emotional_fase_datasets/mouth_open/mouth_open.{i:06}.ply\")\n",
        "\n",
        "data_loader = prepare_data_from_ply(file_names, num_points=num_points, device=device)\n",
        "print(len(data_loader))\n",
        "\n",
        "# VAEモデル構築\n",
        "vae = ISAB_VQVAE(num_points=5000, dim_input=3, dim_hidden=128, num_heads=4, num_inds=32,\n",
        "                 embedding_dim=3, num_embeddings=32).to(device)\n",
        "# W&B watch\n",
        "wandb.watch(vae, log=\"all\", log_freq=100)\n",
        "\n",
        "optimizer = optim.Adam(vae.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "FWFqKiFRllyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets logging to WandB"
      ],
      "metadata": {
        "id": "uwkxq0EfWEub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import numpy as np\n",
        "\n",
        "# Log the dataset as a WandB artifact\n",
        "artifact = wandb.Artifact('face_dataset', type='dataset')\n",
        "\n",
        "# Example: save data to a .npy file\n",
        "dataset_filepath = \"face_dataset.npy\"\n",
        "all_data = []\n",
        "\n",
        "for batch in data_loader:\n",
        "    batch_cpu = [tensor.cpu().numpy() for tensor in batch]\n",
        "    all_data.extend(batch_cpu)\n",
        "\n",
        "np.save(dataset_filepath, np.array(all_data))\n",
        "\n",
        "# Add the saved data file to the artifact\n",
        "artifact.add_file(dataset_filepath)\n",
        "\n",
        "# Log the artifact\n",
        "wandb.log_artifact(artifact)"
      ],
      "metadata": {
        "id": "ZNkmjddGVOyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for batch in data_loader:\n",
        "    points = batch[0].squeeze(0)  # (1, 5000, 3) → (5000, 3)\n",
        "    points = points.cpu().numpy()\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    ax.scatter(points[:, 0], points[:, 1], points[:, 2], s=1, c='b', alpha=0.6)\n",
        "    ax.set_title(\"3D Point Cloud from STL\")\n",
        "    ax.set_xlabel(\"X\")\n",
        "    ax.set_ylabel(\"Y\")\n",
        "    ax.set_zlabel(\"Z\")\n",
        "    ax.view_init(elev=90, azim=-90)\n",
        "\n",
        "    # ★ figを渡す\n",
        "    wandb.log({\"datasets_plot\": wandb.Image(fig)})\n",
        "\n",
        "    #plt.show()\n",
        "    plt.close()\n",
        "    # breakするならここで break\n"
      ],
      "metadata": {
        "id": "QIG7qKThpwwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5000\n",
        "interval = 100\n",
        "rec_error_record = []\n",
        "reg_error_record = []\n",
        "total_error_record = []\n",
        "z_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    vae.train()\n",
        "    running_rec_loss = 0.0\n",
        "    running_quant_loss = 0.0\n",
        "    running_total_loss = 0.0\n",
        "\n",
        "    for batch_idx, (x,) in enumerate(data_loader):\n",
        "        x = x.permute(0, 2, 1).to(device)\n",
        "\n",
        "        z, z_quantized, quant_loss = vae.encode(x)\n",
        "        x_recon_raw, quant_loss, z, _ = vae(x)\n",
        "        x_recon = vae.decode(z)\n",
        "        x_perm = x.permute(0, 2, 1)\n",
        "\n",
        "        rec_loss = F.mse_loss(x_recon, x_perm)\n",
        "        loss = rec_loss + quant_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_rec_loss += rec_loss.item()\n",
        "        running_quant_loss += quant_loss.item()\n",
        "        running_total_loss += loss.item()\n",
        "\n",
        "        if epoch == epochs - 1:\n",
        "            z_list.append(z.cpu().detach().numpy())\n",
        "\n",
        "    num_batches = batch_idx + 1\n",
        "    epoch_rec_loss = running_rec_loss / num_batches\n",
        "    epoch_quant_loss = running_quant_loss / num_batches\n",
        "    epoch_total_loss = running_total_loss / num_batches\n",
        "\n",
        "    rec_error_record.append(epoch_rec_loss)\n",
        "    reg_error_record.append(epoch_quant_loss)\n",
        "    total_error_record.append(epoch_total_loss)\n",
        "\n",
        "    # ここでWandBにロギング\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch,\n",
        "        \"rec_loss\": epoch_rec_loss,\n",
        "        \"quant_loss\": epoch_quant_loss,\n",
        "        \"total_loss\": epoch_total_loss\n",
        "    })\n",
        "\n",
        "    if epoch % interval == 0:\n",
        "        print(f\"[Epoch {epoch}/{epochs}] Rec: {epoch_rec_loss}, Quant: {epoch_quant_loss}, Total: {epoch_total_loss}\")\n",
        "\n",
        "# --- トレーニング後にまとめて保存 ---\n",
        "# 潜在変数\n",
        "if len(z_list) > 0:\n",
        "    z_array = np.array(z_list)\n",
        "    np.save(\"z_list_final.npy\", z_array)\n",
        "    print(f\"z_list saved with shape: {z_array.shape}\")\n",
        "    # WandBに潜在変数もアップロード\n",
        "    wandb.save(\"z_list_final.npy\")\n",
        "else:\n",
        "    print(\"Warning: z_list is empty. Nothing was saved.\")\n",
        "\n",
        "# 重み（モデル）保存\n",
        "torch.save(vae.state_dict(), \"vae_model_final.pth\")\n",
        "wandb.save(\"vae_model_final.pth\")\n",
        "\n",
        "print(\"Training complete and files logged to WandB.\")\n"
      ],
      "metadata": {
        "id": "U1CjCdWHllk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(z_list) # z mu logvar"
      ],
      "metadata": {
        "id": "fD6otq7k92LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 再構成形状の可視化"
      ],
      "metadata": {
        "id": "KsZYm-lPmlyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# z_list_final.npy を読み込んで z_list に変換\n",
        "z_array = np.load(\"z_list_final.npy\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "z_list = [torch.tensor(z_array[i], dtype=torch.float32).to(device) for i in range(z_array.shape[0])]\n",
        "\n",
        "# 可視化用設定\n",
        "num_points = 5000\n",
        "fig, axes = plt.subplots(nrows=6, ncols=3, figsize=(15, 12), subplot_kw={'projection': '3d'})\n",
        "axes = axes.flatten()\n",
        "\n",
        "# 再構成と可視化\n",
        "for index, z in enumerate(z_list):\n",
        "    if index >= len(axes):\n",
        "        break  # 9つのプロットで終了\n",
        "\n",
        "    # 再構築 (z を 1バッチの形に変換して decode)\n",
        "    recon_batch = vae.decode(z)  # z をバッチの形状に変換\n",
        "    print(recon_batch.shape)\n",
        "\n",
        "    # CPU上で detach して numpy に変換\n",
        "    # デコード結果 recon_batch: (1, num_points, 3)\n",
        "    reconst_np = recon_batch.squeeze(0).cpu().detach().numpy()  # -> (num_points, 3)\n",
        "\n",
        "    # 各軸を列インデックスで取得\n",
        "    reconst_x = reconst_np[:, 0]\n",
        "    reconst_y = reconst_np[:, 1]\n",
        "    reconst_z = reconst_np[:, 2]\n",
        "\n",
        "    # プロット\n",
        "    axes[index].view_init(elev=90, azim=-90)\n",
        "    axes[index].scatter(reconst_x, reconst_y, reconst_z, s=1, alpha=0.6)\n",
        "\n",
        "    # 潜在変数の値をフラット化してタイトルに表示\n",
        "    z_flat = z.view(-1).tolist()  # 1次元化\n",
        "    z_str = \", \".join([f\"{value:.2f}\" for value in z_flat])\n",
        "    axes[index].set_title(f\"Latent Variables: {z_str}\")\n",
        "\n",
        "\n",
        "# 最後にプロットを表示\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jIdUdSMURC23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 再構成誤差チェック using CD"
      ],
      "metadata": {
        "id": "8oJV-bQxmcmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "reconstructed_point_cloud=[]\n",
        "# Chamfer Distanceの計算\n",
        "chamfer_distances = []\n",
        "for i, (x,) in enumerate(data_loader):\n",
        "    x = x.to(device)\n",
        "    x = x.squeeze(0)\n",
        "\n",
        "    # Decode z_list[i]\n",
        "    #z = torch.tensor(z_list[i]).to(device)\n",
        "    recon_batch = vae.decode(z_list[i])\n",
        "    # CPU上で detach して numpy に変換\n",
        "    reconst_np = recon_batch.squeeze(0).cpu().detach().numpy()  # -> (num_points, 3)\n",
        "\n",
        "    # 各軸を列インデックスで取得し、Tensor に変換\n",
        "    reconst_x = torch.from_numpy(reconst_np[:, 0])\n",
        "    reconst_y = torch.from_numpy(reconst_np[:, 1])\n",
        "    reconst_z = torch.from_numpy(reconst_np[:, 2])\n",
        "\n",
        "    # Tensor を stack して reconstructed_point_cloud を作成\n",
        "    reconstructed_point_cloud = torch.stack([reconst_x, reconst_y, reconst_z], dim=-1).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "    # 元の点群の形状を整える\n",
        "    original_point_cloud = x.reshape(1, num_points, 3).to(device)\n",
        "\n",
        "    # カスタム関数でChamfer Distanceを計算\n",
        "    loss_cd = chamfer_distance(original_point_cloud, reconstructed_point_cloud)\n",
        "    chamfer_distances.append(loss_cd.item())\n",
        "\n",
        "# Chamfer距離を出力\n",
        "print(\"Chamfer Distances:\", chamfer_distances)\n",
        "average_chamfer_distance = sum(chamfer_distances) / len(chamfer_distances)\n",
        "print(f\"Average Chamfer Distance: {average_chamfer_distance}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Chamfer Distancesの棒グラフをプロット\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(range(len(chamfer_distances)), chamfer_distances, color='skyblue', label='Chamfer Distance')\n",
        "plt.axhline(y=average_chamfer_distance, color='r', linestyle='--', label='Average Chamfer Distance')\n",
        "\n",
        "# グラフの装飾\n",
        "plt.title('Chamfer Distance for Each Sample')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Chamfer Distance')\n",
        "plt.xticks(range(len(chamfer_distances)))\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KgmYbrgn-CHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 再構成誤差チェック using EMD"
      ],
      "metadata": {
        "id": "sTWLEQSsmhn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import ot  # Optimal Transportライブラリ\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# EMDの計算\n",
        "emd_distances = []\n",
        "reconstructed_point_cloud=[]\n",
        "for i, (x,) in enumerate(data_loader):\n",
        "    x = x.to(device)\n",
        "    x = x.squeeze(0)\n",
        "\n",
        "    # Decode z_list[i]\n",
        "    #z = torch.tensor(z_list[i]).to(device)\n",
        "    recon_batch = vae.decode(z_list[i])\n",
        "    # CPU上で detach して numpy に変換\n",
        "    reconst_np = recon_batch.squeeze(0).cpu().detach().numpy()  # -> (num_points, 3)\n",
        "\n",
        "    # 各軸を列インデックスで取得し、Tensor に変換\n",
        "    reconst_x = torch.from_numpy(reconst_np[:, 0])\n",
        "    reconst_y = torch.from_numpy(reconst_np[:, 1])\n",
        "    reconst_z = torch.from_numpy(reconst_np[:, 2])\n",
        "\n",
        "    # Tensor を stack して reconstructed_point_cloud を作成\n",
        "    reconstructed_point_cloud = torch.stack([reconst_x, reconst_y, reconst_z], dim=-1).unsqueeze(0).to(device)\n",
        "    reconstructed_point_cloud = reconstructed_point_cloud.reshape(num_points, 3).to(device)\n",
        "\n",
        "\n",
        "    # 元の点群の形状を整える\n",
        "    original_point_cloud = x.reshape(num_points, 3).to(device)\n",
        "\n",
        "    # カスタム関数でEMDを計算\n",
        "    loss_emd = emd_distance(original_point_cloud, reconstructed_point_cloud)\n",
        "    emd_distances.append(loss_emd)\n",
        "\n",
        "# EMDの結果を出力\n",
        "print(\"EMD Distances:\", emd_distances)\n",
        "average_emd_distance = sum(emd_distances) / len(emd_distances)\n",
        "print(f\"Average EMD Distance: {average_emd_distance}\")\n",
        "\n",
        "# EMDの棒グラフをプロット\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(range(len(emd_distances)), emd_distances, color='lightcoral', label='EMD Distance')\n",
        "plt.axhline(y=average_emd_distance, color='r', linestyle='--', label='Average EMD Distance')\n",
        "\n",
        "# グラフの装飾\n",
        "plt.title('Earth Mover’s Distance for Each Sample')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('EMD Distance')\n",
        "plt.xticks(range(len(emd_distances)))\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fQokDbi0-FE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "ES39jHzsi51K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}